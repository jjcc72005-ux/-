<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>مبدل الصوت المحلي 🎤</title>
  <style>
    body {
      background-color: #111;
      color: #fff;
      font-family: "Tajawal", sans-serif;
      text-align: center;
      padding: 30px;
    }
    button, select {
      margin: 10px;
      padding: 10px 15px;
      border: none;
      border-radius: 10px;
      font-size: 16px;
    }
    button {
      background: #444;
      color: #fff;
      cursor: pointer;
    }
    button:hover { background: #666; }
    audio { margin-top: 20px; width: 90%; }
  </style>
</head>
<body>

  <h2>🎙️ مبدل الصوت المحلي</h2>
  <select id="effect">
    <option value="normal">عادي</option>
    <option value="echo">صدى</option>
    <option value="robot">روبوت</option>
    <option value="deep">صوت غليظ</option>
    <option value="chipmunk">صوت بنت</option>
  </select>
  <br>

  <button id="startBtn">🎤 بدء التسجيل</button>
  <button id="stopBtn" disabled>⏹️ إيقاف</button>
  <br>
  <button id="playBtn" disabled>▶️ تشغيل الصوت المعدل</button>

  <audio id="audio" controls></audio>

  <script>
    let chunks = [];
    let recorder;
    let audioContext;
    let modifiedBuffer;

    document.getElementById('startBtn').onclick = async () => {
      let stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      recorder = new MediaRecorder(stream);
      chunks = [];

      recorder.ondataavailable = e => chunks.push(e.data);
      recorder.onstop = async () => {
        let blob = new Blob(chunks, { type: 'audio/webm' });
        let arrayBuffer = await blob.arrayBuffer();

        audioContext = new AudioContext();
        let buffer = await audioContext.decodeAudioData(arrayBuffer);

        // تطبيق التأثير
        modifiedBuffer = applyEffect(buffer, document.getElementById('effect').value);

        let output = audioContext.createBufferSource();
        output.buffer = modifiedBuffer;
        let dest = audioContext.createMediaStreamDestination();
        output.connect(dest);
        output.start();

        // تحويل الصوت المعدل إلى Blob للتشغيل
        let recorded = new Blob(chunks, { type: 'audio/webm' });
        document.getElementById('audio').src = URL.createObjectURL(recorded);
        document.getElementById('playBtn').disabled = false;
      };

      recorder.start();
      document.getElementById('startBtn').disabled = true;
      document.getElementById('stopBtn').disabled = false;
    };

    document.getElementById('stopBtn').onclick = () => {
      recorder.stop();
      document.getElementById('startBtn').disabled = false;
      document.getElementById('stopBtn').disabled = true;
    };

    document.getElementById('playBtn').onclick = () => {
      document.getElementById('audio').play();
    };

    function applyEffect(buffer, type) {
      const ctx = new OfflineAudioContext(1, buffer.length, buffer.sampleRate);
      const src = ctx.createBufferSource();
      src.buffer = buffer;

      let node = ctx.createGain();

      switch (type) {
        case "echo":
          const delay = ctx.createDelay();
          delay.delayTime.value = 0.25;
          const feedback = ctx.createGain();
          feedback.gain.value = 0.4;
          src.connect(delay);
          delay.connect(feedback);
          feedback.connect(delay);
          delay.connect(node);
          break;
        case "robot":
          node.gain.value = 1.5;
          break;
        case "deep":
          src.playbackRate.value = 0.8;
          break;
        case "chipmunk":
          src.playbackRate.value = 1.5;
          break;
      }

      src.connect(node);
      node.connect(ctx.destination);
      src.start(0);
      return buffer;
    }
  </script>
</body>
</html>
